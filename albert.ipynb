{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('gpu available')\n",
    "    print(torch.cuda.get_device_name())\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('gpu not available')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('train.csv',header=None)\n",
    "df.columns = ['text','mask','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS Sir I created a new env with python 3.7 bu...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>need_help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS above problem how will it solve ?? EOS</td>\n",
       "      <td>O O O O O O O O O</td>\n",
       "      <td>need_help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS Hello sir is there anyone EOS</td>\n",
       "      <td>O O O O O O O</td>\n",
       "      <td>Greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS i think canvas login problem was due to br...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS Please provide me with the link to python ...</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "      <td>community_class_link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  BOS Sir I created a new env with python 3.7 bu...   \n",
       "1         BOS above problem how will it solve ?? EOS   \n",
       "2                  BOS Hello sir is there anyone EOS   \n",
       "3  BOS i think canvas login problem was due to br...   \n",
       "4  BOS Please provide me with the link to python ...   \n",
       "\n",
       "                                                mask                 label  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...             need_help  \n",
       "1                                  O O O O O O O O O             need_help  \n",
       "2                                      O O O O O O O             Greetings  \n",
       "3                O O O O O O O O O O O O O O O O O O                 great  \n",
       "4                              O O O O O O O O O O O  community_class_link  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3514, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_lables = df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "      <th>label_ecoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS Sir I created a new env with python 3.7 bu...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>need_help</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS above problem how will it solve ?? EOS</td>\n",
       "      <td>O O O O O O O O O</td>\n",
       "      <td>need_help</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS Hello sir is there anyone EOS</td>\n",
       "      <td>O O O O O O O</td>\n",
       "      <td>Greetings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS i think canvas login problem was due to br...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>great</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS Please provide me with the link to python ...</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "      <td>community_class_link</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  BOS Sir I created a new env with python 3.7 bu...   \n",
       "1         BOS above problem how will it solve ?? EOS   \n",
       "2                  BOS Hello sir is there anyone EOS   \n",
       "3  BOS i think canvas login problem was due to br...   \n",
       "4  BOS Please provide me with the link to python ...   \n",
       "\n",
       "                                                mask                 label  \\\n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...             need_help   \n",
       "1                                  O O O O O O O O O             need_help   \n",
       "2                                      O O O O O O O             Greetings   \n",
       "3                O O O O O O O O O O O O O O O O O O                 great   \n",
       "4                              O O O O O O O O O O O  community_class_link   \n",
       "\n",
       "   label_ecoded  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             2  \n",
       "4             3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_dict = {}\n",
    "for index,possible_lable in enumerate(possible_lables):\n",
    "    lable_dict[possible_lable] = index\n",
    "    \n",
    "    \n",
    "df['label_ecoded']= df['label'].replace(lable_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =len(possible_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_ecoded\n",
       "0      781\n",
       "8      609\n",
       "1      331\n",
       "13     284\n",
       "27     169\n",
       "      ... \n",
       "112      1\n",
       "113      1\n",
       "115      1\n",
       "116      1\n",
       "150      1\n",
       "Name: count, Length: 151, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_ecoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = df['text'].values\n",
    "labels = df['label_ecoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading albert tokenizer.........\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "\n",
    "print('loading albert tokenizer.........')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2',do_lower_case =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertTokenizer(name_or_path='albert-base-v2', vocab_size=30000, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'cls_token': '[CLS]', 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of Snetence is : 738\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for sent in sents:\n",
    "    input_ids = tokenizer.encode(sent,add_special_tokens=True)\n",
    "    \n",
    "    max_len = max(max_len,len(input_ids))\n",
    "\n",
    "print(f'Max length of Snetence is : {max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 54 but got size 15 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m     input_ids\u001b[38;5;241m.\u001b[39mappend(encoder_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m     attention_mask\u001b[38;5;241m.\u001b[39mappend(encoder_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mcat(input_ids,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 54 but got size 15 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for sent in sents:\n",
    "    \n",
    "    encoder_dict = tokenizer.encode_plus(sent,add_special_tokens=True,max_length=max_len,\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt',\n",
    "                                        truncation=True)\n",
    "    input_ids.append(encoder_dict['input_ids'])\n",
    "    attention_mask.append(encoder_dict['attention_mask'])\n",
    "    \n",
    "    \n",
    "    \n",
    "input_ids = torch.cat(input_ids,dim=0)\n",
    "attention_mask = attention_mask.cat(input_ids,dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "\n",
    "print(f'original sent : {sents[0]}')\n",
    "print(f'input IDS : {input_ids[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from transformers import AlbertTokenizer\n",
    "\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for sent in sents:\n",
    "    encoder_dict = tokenizer.encode_plus(\n",
    "        sent,\n",
    "        add_special_tokens=True,\n",
    "        max_length=100,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='longest',\n",
    "    )\n",
    "    input_ids.append(encoder_dict['input_ids'])\n",
    "    attention_mask.append(encoder_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_mask = torch.cat(attention_mask, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print(f'original sent : {sents[0]}')\n",
    "print(f'input IDS : {input_ids[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2',do_lower_case =True)\n",
    "\n",
    "max_len = 0\n",
    "\n",
    "for sent in sents:\n",
    "    input_ids = tokenizer.encode(sent,add_special_tokens=True)\n",
    "    \n",
    "    max_len = max(max_len,len(input_ids))\n",
    "\n",
    "print(f'Max length of Snetence is : {max_len}')\n",
    "\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for sent in sents:\n",
    "    \n",
    "    encoder_dict = tokenizer.encode_plus(sent,add_special_tokens=True,max_length=max_len,\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt',\n",
    "                                        truncation=True)\n",
    "    input_ids.append(encoder_dict['input_ids'])\n",
    "    attention_mask.append(encoder_dict['attention_mask'])\n",
    "    \n",
    "    \n",
    "    \n",
    "input_ids = torch.cat(input_ids,dim=0)\n",
    "attention_mask = torch.cat(attention_mask,dim=1)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "\n",
    "print(f'original sent : {sents[0]}')\n",
    "print(f'input IDS : {input_ids[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('train.csv', header=None)\n",
    "df.columns = ['text', 'mask', 'label']\n",
    "\n",
    "possible_labels = df['label'].unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "df['label_encoded'] = df['label'].replace(label_dict)\n",
    "\n",
    "sents = df['text'].values\n",
    "labels = df['label_encoded'].values\n",
    "\n",
    "# Initialize the tokenizer\n",
    "print('Loading ALBERT tokenizer...')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
    "\n",
    "max_len = 0\n",
    "\n",
    "for sent in sents:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print(f'Max length of sentence is: {max_len}')\n",
    "\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for sent in sents:\n",
    "    encoder_dict = tokenizer.encode_plus(\n",
    "        sent,\n",
    "        add_special_tokens=True,\n",
    "        max_length=100,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        truncation=True\n",
    "    )\n",
    "    input_ids.append(encoder_dict['input_ids'])\n",
    "    attention_mask.append(encoder_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_mask = torch.cat(attention_mask, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print(f'Original sentence: {sents[0]}')\n",
    "print(f'Input IDs: {input_ids[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ALBERT tokenizer...\n",
      "Original sentence: BOS how to open terminal from the project folder to execute the git command EOS\n",
      "Input IDs: tensor([    2, 11054,   184,    20,   368,  3855,    37,    14,   669, 19294,\n",
      "           20, 15644,    14,    13, 10404,  1202,    13,  3894,    18,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('train.csv', header=None)\n",
    "df.columns = ['text', 'mask', 'label']\n",
    "\n",
    "possible_labels = df['label'].unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "df['label_encoded'] = df['label'].replace(label_dict)\n",
    "\n",
    "sents = df['text'].values\n",
    "labels = df['label_encoded'].values\n",
    "\n",
    "# Initialize the tokenizer\n",
    "print('Loading ALBERT tokenizer...')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
    "\n",
    "max_len = 0\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for sent in sents:\n",
    "    encoder_dict = tokenizer.encode_plus(\n",
    "        sent,\n",
    "        add_special_tokens=True,\n",
    "        max_length=100,\n",
    "        return_attention_mask=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    input_ids.append(encoder_dict['input_ids'])\n",
    "    attention_mask.append(encoder_dict['attention_mask'])\n",
    "\n",
    "max_len = max(len(ids) for ids in input_ids)\n",
    "\n",
    "# Pad the input_ids and attention_mask tensors\n",
    "input_ids = [ids + [tokenizer.pad_token_id] * (max_len - len(ids)) for ids in input_ids]\n",
    "attention_mask = [mask + [0] * (max_len - len(mask)) for mask in attention_mask]\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print(f'Original sentence: {sents[20]}')\n",
    "print(f'Input IDs: {input_ids[20]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
